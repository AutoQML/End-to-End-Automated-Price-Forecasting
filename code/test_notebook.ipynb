{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Value    Status\n",
      "0        A     10    Active\n",
      "1        B     20  Inactive\n",
      "2        A     30    Active\n",
      "3        C     40    Active\n",
      "     0    1    2    3    4     5\n",
      "0  1.0  0.0  0.0  1.0  0.0  10.0\n",
      "1  0.0  1.0  0.0  0.0  1.0  20.0\n",
      "2  1.0  0.0  0.0  1.0  0.0  30.0\n",
      "3  0.0  0.0  1.0  1.0  0.0  40.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Category': ['A', 'B', 'A', 'C'],\n",
    "        'Value': [10, 20, 30, 40],\n",
    "        'Status': ['Active', 'Inactive', 'Active', 'Active']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Define which columns to encode\n",
    "columns_to_encode = ['Category', 'Status']\n",
    "\n",
    "# Create a ColumnTransformer\n",
    "# The transformers parameter takes a list of tuples where each tuple consists of a name, a transformer, and a list of columns\n",
    "# In this case, we apply OneHotEncoder to the specified columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(), columns_to_encode)\n",
    "    ],\n",
    "    remainder='passthrough'  # This means that the remaining columns will not be affected\n",
    ")\n",
    "\n",
    "# Fit and transform the data\n",
    "transformed_data = preprocessor.fit_transform(df)\n",
    "\n",
    "transformed_data = pd.DataFrame(transformed_data)\n",
    "\n",
    "# Print the transformed data\n",
    "print(transformed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values for df_cat_encoded:\n",
      "    Category_A  Category_B  Category_C  Status_Active  Status_Inactive\n",
      "0         1.0         0.0         0.0            1.0              0.0\n",
      "1         0.0         1.0         0.0            0.0              1.0\n",
      "2         1.0         0.0         0.0            1.0              0.0\n",
      "3         0.0         0.0         1.0            1.0              0.0\n",
      "Values for scaled_df_cat:\n",
      "    Category_A  Category_B  Category_C  Status_Active  Status_Inactive\n",
      "0         1.0   -0.577350   -0.577350       0.577350        -0.577350\n",
      "1        -1.0    1.732051   -0.577350      -1.732051         1.732051\n",
      "2         1.0   -0.577350   -0.577350       0.577350        -0.577350\n",
      "3        -1.0   -0.577350    1.732051       0.577350        -0.577350\n",
      "Values for scaled_df_num:\n",
      "       Value\n",
      "0 -1.341641\n",
      "1 -0.447214\n",
      "2  0.447214\n",
      "3  1.341641\n",
      "Values for combined_df:\n",
      "    Category_A  Category_B  Category_C  Status_Active  Status_Inactive  \\\n",
      "0         1.0   -0.577350   -0.577350       0.577350        -0.577350   \n",
      "1        -1.0    1.732051   -0.577350      -1.732051         1.732051   \n",
      "2         1.0   -0.577350   -0.577350       0.577350        -0.577350   \n",
      "3        -1.0   -0.577350    1.732051       0.577350        -0.577350   \n",
      "\n",
      "      Value  \n",
      "0 -1.341641  \n",
      "1 -0.447214  \n",
      "2  0.447214  \n",
      "3  1.341641  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'Category': ['A', 'B', 'A', 'C'],\n",
    "        'Value': [10, 20, 30, 40],\n",
    "        'Status': ['Active', 'Inactive', 'Active', 'Active']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# print(df.columns)\n",
    "cat_features = ['Category', 'Status']\n",
    "\n",
    "# separate numerical and categorical columns\n",
    "df_cat = df[cat_features].copy()\n",
    "df_num = df.drop(cat_features, axis=1)\n",
    "\n",
    "# get the column names\n",
    "cat_feature_names = df_cat.columns\n",
    "num_feature_names = df_num.columns\n",
    "\n",
    "# print(df_cat)\n",
    "# print(df_num)\n",
    "# print(\"Cat names: \", df_cat.columns)\n",
    "\n",
    "# Define which columns to encode\n",
    "columns_to_encode = ['Category', 'Status']\n",
    "\n",
    "#fit encoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(df_cat)\n",
    "\n",
    "#transform categorical features\n",
    "X_encoded = enc.transform(df_cat).toarray()\n",
    "\n",
    "#create feature matrix\n",
    "new_cat_feature_names = enc.get_feature_names_out(cat_feature_names)\n",
    "\n",
    "df_cat_encoded = pd.DataFrame(X_encoded, columns= new_cat_feature_names)\n",
    "\n",
    "print(f\"Values for df_cat_encoded:\\n {df_cat_encoded}\")\n",
    "\n",
    "# Initialize the StandardScaler for df_cat_encoded\n",
    "scaler_df_cat_encoded = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler_df_cat_encoded.fit_transform(df_cat_encoded)\n",
    "\n",
    "# Convert the scaled data back to a dataframe\n",
    "scaled_df_cat = pd.DataFrame(scaled_data, columns=new_cat_feature_names)\n",
    "\n",
    "print(f\"Values for scaled_df_cat:\\n {scaled_df_cat}\")\n",
    "\n",
    "\n",
    "# Initialize the StandardScaler for df_num\n",
    "scaler_df_num = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler_df_num.fit_transform(df_num)\n",
    "\n",
    "# Convert the scaled data back to a dataframe\n",
    "scaled_df_num = pd.DataFrame(scaled_data, columns=num_feature_names)\n",
    "\n",
    "print(f\"Values for scaled_df_num:\\n {scaled_df_num}\")\n",
    "\n",
    "combined_df = pd.concat([scaled_df_cat, scaled_df_num], axis=1)\n",
    "\n",
    "print(f\"Values for combined_df:\\n {combined_df}\")\n",
    "\n",
    "\n",
    "\n",
    "# combined_df = pd.concat([X, df_num], axis=1)\n",
    "\n",
    "# print(f\"Values for combined_df:\\n {combined_df}\")\n",
    "\n",
    "# # Extract the column names\n",
    "# columns = combined_df.columns\n",
    "\n",
    "# # Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Fit and transform the data\n",
    "# scaled_data = scaler.fit_transform(combined_df)\n",
    "\n",
    "# # Convert the scaled data back to a dataframe\n",
    "# scaled_df = pd.DataFrame(scaled_data, columns=columns)\n",
    "\n",
    "# print(f\"Values for scaled_df:\\n {scaled_df}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lead_preproc_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
